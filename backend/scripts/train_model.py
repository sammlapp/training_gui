#!/usr/bin/env python3
"""
Training script for bioacoustics models
Handles model training with active learning capabilities
"""
import argparse
import logging
import pandas as pd
import json
import sys
import os
import torch

import sklearn.model_selection
from pathlib import Path
import datetime
from opensoundscape.ml.shallow_classifier import fit_classifier_on_embeddings
from opensoundscape.ml.cnn import _gpu_if_available

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)

# configuration: might eventually expose these parameters
max_background_samples = 10_000
overlay_weight = (0.2, 0.5)


def check_clip_df_format(df):
    assert df.index.names == (
        "file",
        "start_time",
        "end_time",
    ), f"expected the first 3 columns of the csv to be `file,start_time,end_time` but got {df.index.names}"


def load_config_file(config_path):
    """Load training configuration from JSON file"""
    try:
        with open(config_path, "r") as f:
            config = json.load(f)
        return config
    except Exception as e:
        logger.error(f"Failed to load config file {config_path}: {e}")
        raise


def load_model(model_name):
    """Load a model from the bioacoustics model zoo"""
    try:
        logger.info(f"Loading model: {model_name}")

        # Import here to avoid import errors if not installed
        import bioacoustics_model_zoo as bmz
        import pydantic.deprecated.decorator  # Fix for pydantic error

        # Load model using the same approach as inference
        model = getattr(bmz, model_name)()
        logger.info(f"Model loaded successfully: {type(model).__name__}")
        return model
    except ImportError as e:
        logger.error(
            f"Import error - make sure bioacoustics_model_zoo is installed: {e}"
        )
        raise
    except AttributeError as e:
        logger.error(f"Model {model_name} not found in bioacoustics_model_zoo: {e}")
        raise
    except Exception as e:
        logger.error(f"Failed to load model {model_name}: {e}")
        raise


def process_fully_annotated_files(config):
    """Load and process fully annotated files"""
    fully_annotated_dfs = []

    for f in config.get("fully_annotated_files", []):
        logger.info(f"Loading fully annotated file: {f}")
        df = pd.read_csv(f, index_col=[0, 1, 2])
        check_clip_df_format(df)

        # columns are either one per class with one-hot labels, or "labels" and "complete"
        if "labels" in df.columns:
            # parse labels column (list of strings) to list
            import ast

            df["labels"] = df["labels"].apply(ast.literal_eval)
            df = df[df.complete == "complete"]

            # use opensoundscape utility for labels to one-hot
            from opensoundscape.annotations import categorical_to_multi_hot

            multihot_labels = pd.DataFrame(
                categorical_to_multi_hot(
                    df["labels"].values, classes=config["class_list"], sparse=False
                ),
                index=df.index,
                columns=config["class_list"],
            )
        else:
            # df should have one-hot labels: just select the correct classes
            multihot_labels = df[config["class_list"]]

        fully_annotated_dfs.append(multihot_labels)

    if fully_annotated_dfs:
        return pd.concat(fully_annotated_dfs)[config["class_list"]]
    else:
        return pd.DataFrame(columns=config["class_list"])


def process_single_class_annotations(config, labels):
    """Load and process single class annotation files"""
    # add labels where only one species was annotated
    # treat other species as weak negatives
    single_class_dfs = []

    for annotation_item in config.get("single_class_annotations", []):
        file_path = annotation_item["file"]
        class_name = annotation_item["class"]

        logger.info(
            f"Loading single class annotation file: {file_path} for class: {class_name}"
        )
        df = pd.read_csv(file_path, index_col=[0, 1, 2])
        check_clip_df_format(df)

        # remove incomplete or uncertain annotations
        df = df[df.annotation.isin(["yes", "no"])]

        # create one-hot df
        new_labels = pd.DataFrame(index=df.index, columns=config["class_list"])
        new_labels[class_name] = df["annotation"].map({"yes": 1, "no": 0})

        # TODO: loss function should be able to handle NaNs by using a custom, small relative class weight
        new_labels = new_labels.fillna(0)
        single_class_dfs.append(new_labels)

    if single_class_dfs:
        single_labels = pd.concat(single_class_dfs)
        # Combine with fully annotated labels
        if not labels.empty:
            labels = pd.concat([labels, single_labels])
        else:
            labels = single_labels

    return labels


def load_background_samples(config):
    """Load background samples if provided

    This would typically be environmental noise with none of the classes present

    Samples are used for overlay (aka mixup) in which the sample is blended with a training sample

    # TODO: allow selecting a folder of audio or list of files instead of providing df?
    """
    background_samples_file = config.get("background_samples_file", "")
    if background_samples_file and os.path.exists(background_samples_file):
        logger.info(f"Loading background samples from: {background_samples_file}")
        background_samples = pd.read_csv(background_samples_file, index_col=[0, 1, 2])
        check_clip_df_format(background_samples)

        # subset to a maximum of 10,000, which should be plenty of variety
        if len(background_samples) > max_background_samples:
            background_samples = background_samples.sample(n=max_background_samples)

        return background_samples
    return None


def load_evaluation_data(config):
    """Load evaluation data if provided"""
    evaluation_file = config.get("evaluation_file", "")
    if evaluation_file and os.path.exists(evaluation_file):
        logger.info(f"Loading evaluation data from: {evaluation_file}")
        return pd.read_csv(evaluation_file, index_col=[0, 1, 2])
    return None


def run_training(config):
    """Run the training process"""
    try:
        # Create output directory
        model_save_path = config.get("model_save_path")
        out_dir = Path(model_save_path).parent
        out_dir.mkdir(parents=True, exist_ok=True)
        # Save configuration
        config_save_path = config.get(
            "config_output_path", str(out_dir / "training_config.json")
        )
        Path(config_save_path).parent.mkdir(parents=True, exist_ok=True)
        with open(config_save_path, "w") as f:
            json.dump(config, f, indent=4)

        # Log training start information
        logger.info("=" * 80)
        logger.info("BIOACOUSTICS MODEL TRAINING STARTED")
        logger.info("=" * 80)
        logger.info(f"Timestamp: {datetime.datetime.now().isoformat()}")
        logger.info(f"Model: {config.get('model', 'Unknown')}")
        logger.info(f"Target classes: {config.get('class_list', [])}")
        logger.info(f"Save location: {config.get('model_save_path')}")

        # Log configuration summary
        training_settings = config.get("training_settings", {})
        logger.info(f"Training settings:")
        logger.info(f"  - Batch size: {training_settings.get('batch_size', 32)}")
        logger.info(f"  - Number of workers: {training_settings.get('num_workers', 4)}")
        logger.info(
            f"  - Freeze feature extractor: {training_settings.get('freeze_feature_extractor', True)}"
        )
        logger.info(
            f"  - Multi-layer classifier: {training_settings.get('classifier_hidden_layer_sizes') is not None}"
        )
        if training_settings.get("classifier_hidden_layer_sizes"):
            logger.info(
                f"  - Hidden layer sizes: {training_settings.get('classifier_hidden_layer_sizes')}"
            )
        logger.info("")

        # Load and process annotation data
        logger.info("Processing fully annotated files...")
        labels = process_fully_annotated_files(config)

        logger.info("Processing single class annotations...")
        labels = process_single_class_annotations(config, labels)

        if labels.empty:
            raise ValueError("No training data found. Please provide annotation files.")

        logger.info(f"Total training samples: {len(labels)}")
        logger.info(f"Classes: {config['class_list']}")

        # Split data for training/validation
        evaluation_df = load_evaluation_data(config)
        if evaluation_df is None:
            logger.info("No evaluation file provided, using train/validation split")
            train_df, evaluation_df = sklearn.model_selection.train_test_split(
                labels, test_size=0.2, random_state=42
            )
        else:
            train_df = labels
            logger.info(
                f"Using provided evaluation set with {len(evaluation_df)} samples"
            )

        logger.info(f"Training samples: {len(train_df)}")
        logger.info(f"Validation samples: {len(evaluation_df)}")

        # Load pre-trained model
        model_name = config.get("model")
        logger.info(f"Loading model: {model_name}")
        model = load_model(model_name)

        logger.info(f" Using device: {model.device}")

        # Configure model for target classes
        # if model.classes != config["class_list"]: (always initialize new classifier for now)
        logger.info(
            "Initializing new classifier head with random weights"  # , because classes differ from the loaded classifier head"
        )
        from opensoundscape.ml.shallow_classifier import MLPClassifier
        from opensoundscape.ml.cnn_architectures import set_layer_from_name

        # changes .classes and updates metrics as needed; initializes 1-layer classifier
        model.change_classes(config["class_list"])
        # initialize multi-layer classifier if needed:

        hidden_layer_sizes = config.get("training_settings", {}).get(
            "classifier_hidden_layer_sizes"
        )

        if hidden_layer_sizes and len(hidden_layer_sizes) > 0:
            assert all(
                [isinstance(x, int) for x in hidden_layer_sizes]
            ), "hidden_layer_sizes must be a list of integers"
            new_classifier = MLPClassifier(
                input_size=model.classifier.in_features,
                output_size=len(config["class_list"]),
                hidden_layer_sizes=hidden_layer_sizes,
            )
            clf_layer_name = model.network.classifier_layer
            set_layer_from_name(model.network, clf_layer_name, new_classifier)

        # Optionally freeze feature extractor
        if training_settings.get("freeze_feature_extractor", True):
            logger.info("Freezing feature extractor")
            model.freeze_feature_extractor()

        # Customize preprocessing

        # Load background samples (optional) for overlay
        background_samples = load_background_samples(config)
        if background_samples is not None:
            from opensoundscape.preprocess.overlay import Overlay

            logger.info(
                f"Using {len(background_samples)} background samples for overlay in preprocessor"
            )
            # TODO: consider allowing user to select which training sets get overlays (criterion_fn=...)
            overlay_action = Overlay(
                overlay_df=background_samples,
                update_labels=False,
                overlay_prob=0.75,
                max_overlay_num=1,
                overlay_weight=overlay_weight,
                # criterion_fn=)
            )
            model.preprocessor.insert_action(
                action_index="background_sample_overlay",
                action=overlay_action,
                after_key="to_spec",
            )

        # configure settings form config file or use defaults
        batch_size = training_settings.get("batch_size", 32)
        num_workers = training_settings.get("num_workers", 0)

        # Set audio root if provided
        audio_root = config.get("root_audio_folder", None)

        # Run on a small subset of data if specified
        if "subset_size" in config and isinstance(config["subset_size"], int):
            subset_size = min(config["subset_size"], len(train_df))
            logger.info(
                f"Using a SUBSET of {subset_size} samples for training and evaluation"
            )
            train_df = train_df.sample(n=subset_size, random_state=0)
            evaluation_df = evaluation_df.sample(n=subset_size, random_state=0)

        # training strategy depends on whether the feature extractor is frozen
        # if it is frozen, we can quickly train the classifier head on embeddings
        # if it is not frozen, we need to train the entire model

        if config.get("freeze_feature_extractor", True):
            logger.info(
                "Feature extractor is frozen. Training will only update the classifier head (fast)."
            )
            # Default epochs (steps) for shallow classifier fitting
            # we typically train lots of steps since its very fast from here forward
            # and we can use early stopping to avoid overfitting
            epochs = training_settings.get("epochs", 1000)

            # create embeddings once and use them for quickly training the classifier head
            # after fitting, this function loads the weights of the best step
            _, _, _, _, metrics = fit_classifier_on_embeddings(
                embedding_model=model,
                classifier_model=model.network.classifier,
                train_df=train_df,
                validation_df=evaluation_df,
                n_augmentation_variants=training_settings.get(
                    "n_augmentation_variants", 5
                ),
                audio_root=audio_root,
                embedding_batch_size=batch_size,
                embedding_num_workers=num_workers,
                steps=epochs,
                optimizer=None,
                criterion=None,
                device=model.device,  # auto-selected to GPU if available
                early_stopping_patience=None,  # should we allow early stopping?
                logging_interval=100,
                validation_interval=1,
            )

            # save the model
            model.save(model_save_path, pickle=True)
            logger.info(f"Saved trained model to: {model_save_path}")
        else:
            logger.info(
                "Feature extractor is not frozen. Training will update the entire model (slow)."
            )
            # Default epochs for full training
            epochs = training_settings.get("epochs", 20)
            try:
                assert "class" in model.optimizer_params
                # use AdamW optimizer with custom parameters
                model.optimizer_params = {
                    "class": torch.optim.AdamW,
                    "kwargs": {
                        "lr": training_settings.get("feature_extractor_lr", 0.001)
                    },
                    "classifier_lr": training_settings.get("classifier_lr", 0.01),
                }
            except:
                logger.warning(
                    "Model does not support custom optimizer parameters. Using default learning rate and optimizer."
                )
            try:
                assert "class" in model.lr_scheduler_params
                model.lr_scheduler_params = {
                    "class": torch.optim.lr_scheduler.CosineAnnealingLR,
                    "kwargs": {
                        "T_max": epochs,
                        "eta_min": training_settings.get("min_lr", 1e-6),
                    },
                }
            except:
                logger.warning(
                    "Model does not support custom learning rate scheduler parameters. Using default scheduler."
                )
            # Start training loop
            logger.info("Starting model training...")
            model.train(
                train_df,
                evaluation_df,
                epochs=epochs,
                batch_size=batch_size,
                num_workers=num_workers,
                save_path=out_dir,
                save_interval=-1,  # Only save best epoch (saves best.pkl)
                audio_root=audio_root,
            )
            metrics = model.valid_metrics[model.best_epoch]

        logger.info("Training completed successfully!")

        # Get validation metrics
        logger.info(f"Final validation metrics: {metrics}")

        # Output summary for the GUI
        summary = {
            "status": "success",
            "model_save_path": model_save_path,
            "config_save_path": config_save_path,
            "training_samples": len(train_df),
            "validation_samples": len(evaluation_df),
            "classes_trained": config["class_list"],
            "epochs_completed": epochs,
            "final_metrics": metrics,
        }

        logger.info("=" * 80)
        logger.info("TRAINING COMPLETED SUCCESSFULLY!")
        logger.info("=" * 80)
        logger.info(f"Model saved to: {model_save_path}")
        logger.info(f"Training samples processed: {len(train_df)}")
        logger.info(f"Validation samples: {len(evaluation_df)}")
        logger.info(f"Final timestamp: {datetime.datetime.now().isoformat()}")
        logger.info(f"Final validation metrics: {metrics}")
        logger.info("=" * 80)
        print(json.dumps(summary))

    except Exception as e:
        logger.error("=" * 80)
        logger.error("TRAINING FAILED!")
        logger.error("=" * 80)
        logger.error(f"Error: {e}")
        logger.error(f"Timestamp: {datetime.datetime.now().isoformat()}")
        import traceback

        logger.error(f"Full traceback:")
        logger.error(traceback.format_exc())
        logger.error("=" * 80)
        error_summary = {"status": "error", "error": str(e)}
        print(json.dumps(error_summary))
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="Run bioacoustics model training")
    parser.add_argument(
        "--config", required=True, help="Path to training configuration file"
    )
    args = parser.parse_args()

    # Load configuration from file
    config_data = load_config_file(args.config)

    # Run training
    run_training(config_data)


if __name__ == "__main__":
    main()
