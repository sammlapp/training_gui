# Dipper Server Mode Configuration
#
# Copy this file to server_config.yml and customize for your setup
#

server:
  # Host to bind Python backend to
  # Use 0.0.0.0 to accept connections from any network interface
  # Use 127.0.0.1 for localhost only
  host: 0.0.0.0

  # Port for Python backend (ML tasks and API)
  port: 8000

  # Port for static file server (React app)
  static_port: 3000

file_access:
  # List of base directories that the app can access
  # Add your audio data directories here
  allowed_base_paths:
    - /home/username/audio_data
    - /mnt/bioacoustics
    - /data/recordings
    # macOS example:
    # - /Users/username/Documents/audio
    # Windows example:
    # - C:/Users/username/Documents/audio

jobs:
  # Maximum number of concurrent ML tasks (inference, training, extraction)
  # Adjust based on your server's RAM and CPU
  # Each task typically uses 2-4GB RAM
  max_concurrent: 3

logging:
  # Logging level: DEBUG, INFO, WARNING, ERROR
  level: INFO

  # Log file locations (optional)
  # If not specified, logs go to stdout/stderr
  # python_backend: /var/log/dipper/backend.log
  # static_server: /var/log/dipper/static.log
